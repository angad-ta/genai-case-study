{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"zbzKE8XCIAnH","executionInfo":{"status":"ok","timestamp":1702037891554,"user_tz":-330,"elapsed":6322,"user":{"displayName":"Nichol Dsouza","userId":"00331130812712411638"}}},"outputs":[],"source":["!pip install -q evaluate transformers accelerate bitsandbytes peft"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"vmOLBy4ORnV3","executionInfo":{"status":"ok","timestamp":1702037914929,"user_tz":-330,"elapsed":23380,"user":{"displayName":"Nichol Dsouza","userId":"00331130812712411638"}}},"outputs":[],"source":["from transformers import AutoTokenizer, AutoModelForCausalLM\n","from evaluate import load\n","from datasets import load_from_disk , Dataset\n","from peft import PeftModel, PeftConfig\n","import pandas as pd"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"VVkq6R3WS76j","executionInfo":{"status":"ok","timestamp":1702037914929,"user_tz":-330,"elapsed":13,"user":{"displayName":"Nichol Dsouza","userId":"00331130812712411638"}}},"outputs":[],"source":["model_name_or_path = \"databricks/dolly-v2-3b\"\n","tokenizer_name_or_path = \"databricks/dolly-v2-3b\"\n","peft_model_path = \"/content/drive/MyDrive/Colab Notebooks/Table to insights/dolly/prefix_tuned_model_1200\"\n","text_column = \"prompt\"\n","label_column = \"label\"\n","max_length = 1200"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"YypbIHnfTOXY","executionInfo":{"status":"ok","timestamp":1702037914930,"user_tz":-330,"elapsed":13,"user":{"displayName":"Nichol Dsouza","userId":"00331130812712411638"}}},"outputs":[],"source":["# Specify the directory where the dataset is saved\n","saved_directory = \"/content/drive/MyDrive/Colab Notebooks/Table to insights/Data/Analytical Datset\"\n","\n","# Load the dataset from the specified directory\n","dataset = load_from_disk(saved_directory)\n","dataset = dataset['validation']"]},{"cell_type":"code","source":["# The below code is not working as its finishing the memory on free Collab\n","# the general idea is to have a final dataframe with 3 column the 1st column\n","# is the human baseline (Label in analytical datset) , 2nd column is\n","# the inference from base model (model without fine tuning) and the 3rd column\n","# is to get inference of peft model (model with fine tuning)\n","# if this dataframe is created then generating the rouge and blue metrics is\n","# trivial"],"metadata":{"id":"dZGrXv2JY7ja"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"1yS1Oe7ZY7mS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"ke8r3TrmY7p5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def generate_summary(model, tokenizer, query, max_length=1024):\n","    input_ids = tokenizer.encode(query, return_tensors=\"pt\", max_length=max_length, padding=\"max_length\", truncation=True)\n","    summary_ids = model.generate(input_ids, max_length=150, num_beams=4, length_penalty=2.0, early_stopping=True)\n","    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n","    return summary\n","\n","def summarize_example(example, model, tokenizer, text_column, label_column):\n","    prompt = example[text_column]\n","    label = example[label_column]\n","    model_summary = generate_summary(model, tokenizer, prompt)\n","    return {\"prompt\": prompt, \"label\": label, \"model_summary\": model_summary}"],"metadata":{"id":"ez3ZJa9UKjVR","executionInfo":{"status":"ok","timestamp":1702037914930,"user_tz":-330,"elapsed":12,"user":{"displayName":"Nichol Dsouza","userId":"00331130812712411638"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["def process_model_and_save_results(tokenizer_name_or_path, model_name_or_path, peft_model_path, dataset, text_column, label_column, batch_size=8, chunk_size=32):\n","    tokenizer = AutoTokenizer.from_pretrained(tokenizer_name_or_path)\n","    base_model = AutoModelForCausalLM.from_pretrained(model_name_or_path, load_in_8bit=True, device_map=\"auto\")\n","\n","    config = PeftConfig.from_pretrained(peft_model_path)\n","    peft_base_model = AutoModelForCausalLM.from_pretrained(config.base_model_name_or_path,load_in_8bit=True,device_map=\"auto\")\n","    peft_tuned_model = PeftModel.from_pretrained(peft_base_model, peft_model_path)\n","    del peft_base_model\n","\n","    tqdm_desc_base = \"Processing base model\"\n","    tqdm_desc_tuned = \"Processing fine-tuned model\"\n","\n","    summarize = lambda examples, model: [summarize_example(example, model, tokenizer, text_column, label_column) for example in examples]\n","\n","    # Process the base model in chunks\n","    df_base_list = []\n","    for i in range(0, len(dataset), chunk_size):\n","        chunk = dataset[i:i+chunk_size]\n","        chunk = Dataset.from_dict(chunk)\n","        df_base_chunk = pd.DataFrame(chunk.map(summarize, batched=True, batch_size=batch_size, desc=tqdm_desc_base))\n","        df_base_list.append(df_base_chunk)\n","\n","    df_base = pd.concat(df_base_list, axis=0)\n","\n","    # Free up memory by deleting the base model\n","    del base_model\n","\n","    # Process the fine-tuned model in chunks\n","    df_tuned_list = []\n","    for i in range(0, len(dataset), chunk_size):\n","        chunk = dataset[i:i+chunk_size]\n","        chunk = Dataset.from_dict(chunk)\n","        df_tuned_chunk = pd.DataFrame(chunk.map(summarize, batched=True, batch_size=batch_size, desc=tqdm_desc_tuned))\n","        df_tuned_list.append(df_tuned_chunk)\n","\n","    df_tuned = pd.concat(df_tuned_list, axis=0)\n","\n","    df_final = pd.concat([df_base, df_tuned], axis=1)\n","    return df_final"],"metadata":{"id":"ncR3Ez3MNYC5","executionInfo":{"status":"ok","timestamp":1702037914930,"user_tz":-330,"elapsed":12,"user":{"displayName":"Nichol Dsouza","userId":"00331130812712411638"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["results = process_model_and_save_results(tokenizer_name_or_path, model_name_or_path, peft_model_path, dataset, text_column, label_column, batch_size=8, chunk_size=10)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":353,"referenced_widgets":["09d1803fb2a446cf8aefa52f15395659","b2841163856c4163a0567c58ef345b54","0d77d1a822834e9f86564bfbfc2cc2d5","68bf4d323eb3494aa1ae30a9bf9f8324","8d122cfdb4ec4cdaacd9ab2b086e02c8","ada487ebafa94fb1af6ed7d5db8c02e4","e5be7eca407144b5b8e55edd794d3fff","fce1711007e242949a68e3f7e0802b3a","c77ea19bfd1345b5a8863051f873ff79","bea0cb9c7f5647a4a56f83a345b6c17a","32ca9d8a5da64488b128c0c50bdb4647"]},"id":"ArFKvnvmT3sX","executionInfo":{"status":"error","timestamp":1702038100142,"user_tz":-330,"elapsed":185224,"user":{"displayName":"Nichol Dsouza","userId":"00331130812712411638"}},"outputId":"22f7844a-6919-4187-f790-b1b9b8f0a55f"},"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":["Processing base model:   0%|          | 0/10 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"09d1803fb2a446cf8aefa52f15395659"}},"metadata":{}},{"output_type":"error","ename":"TypeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-7-dc8d5a24c260>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess_model_and_save_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenizer_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpeft_model_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext_column\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_column\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunk_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-6-65b1f5d2f365>\u001b[0m in \u001b[0;36mprocess_model_and_save_results\u001b[0;34m(tokenizer_name_or_path, model_name_or_path, peft_model_path, dataset, text_column, label_column, batch_size, chunk_size)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mchunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mchunk_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mchunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mdf_base_chunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msummarize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatched\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtqdm_desc_base\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0mdf_base_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_base_chunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    589\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"Dataset\"\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"self\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m         \u001b[0;31m# apply actual function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 591\u001b[0;31m         \u001b[0mout\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Dataset\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"DatasetDict\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    592\u001b[0m         \u001b[0mdatasets\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Dataset\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    554\u001b[0m         }\n\u001b[1;32m    555\u001b[0m         \u001b[0;31m# apply actual function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 556\u001b[0;31m         \u001b[0mout\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Dataset\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"DatasetDict\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    557\u001b[0m         \u001b[0mdatasets\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Dataset\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m         \u001b[0;31m# re-apply format to the output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, suffix_template, new_fingerprint, desc)\u001b[0m\n\u001b[1;32m   3087\u001b[0m                     \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdesc\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m\"Map\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3088\u001b[0m                 ) as pbar:\n\u001b[0;32m-> 3089\u001b[0;31m                     \u001b[0;32mfor\u001b[0m \u001b[0mrank\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_single\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mdataset_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3090\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3091\u001b[0m                             \u001b[0mshards_done\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36m_map_single\u001b[0;34m(shard, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, new_fingerprint, rank, offset)\u001b[0m\n\u001b[1;32m   3464\u001b[0m                         )  # Something simpler?\n\u001b[1;32m   3465\u001b[0m                         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3466\u001b[0;31m                             batch = apply_function_on_filtered_inputs(\n\u001b[0m\u001b[1;32m   3467\u001b[0m                                 \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3468\u001b[0m                                 \u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36mapply_function_on_filtered_inputs\u001b[0;34m(pa_inputs, indices, check_same_num_examples, offset)\u001b[0m\n\u001b[1;32m   3343\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mwith_rank\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3344\u001b[0m                 \u001b[0madditional_args\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mrank\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3345\u001b[0;31m             \u001b[0mprocessed_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfn_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0madditional_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfn_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3346\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessed_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLazyDict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3347\u001b[0m                 processed_inputs = {\n","\u001b[0;31mTypeError\u001b[0m: process_model_and_save_results.<locals>.<lambda>() missing 1 required positional argument: 'model'"]}]},{"cell_type":"code","source":["#"],"metadata":{"id":"xadYiLK2W7L6","executionInfo":{"status":"aborted","timestamp":1702038100143,"user_tz":-330,"elapsed":4,"user":{"displayName":"Nichol Dsouza","userId":"00331130812712411638"}}},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[],"gpuType":"T4","mount_file_id":"1epbnUC19ewZWgPMqdJsOsJr4A11rwSQB","authorship_tag":"ABX9TyNk3Sd1G82Uvrie90l3U7Qu"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"09d1803fb2a446cf8aefa52f15395659":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b2841163856c4163a0567c58ef345b54","IPY_MODEL_0d77d1a822834e9f86564bfbfc2cc2d5","IPY_MODEL_68bf4d323eb3494aa1ae30a9bf9f8324"],"layout":"IPY_MODEL_8d122cfdb4ec4cdaacd9ab2b086e02c8"}},"b2841163856c4163a0567c58ef345b54":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ada487ebafa94fb1af6ed7d5db8c02e4","placeholder":"​","style":"IPY_MODEL_e5be7eca407144b5b8e55edd794d3fff","value":"Processing base model:   0%"}},"0d77d1a822834e9f86564bfbfc2cc2d5":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"danger","description":"","description_tooltip":null,"layout":"IPY_MODEL_fce1711007e242949a68e3f7e0802b3a","max":10,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c77ea19bfd1345b5a8863051f873ff79","value":0}},"68bf4d323eb3494aa1ae30a9bf9f8324":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bea0cb9c7f5647a4a56f83a345b6c17a","placeholder":"​","style":"IPY_MODEL_32ca9d8a5da64488b128c0c50bdb4647","value":" 0/10 [00:00&lt;?, ? examples/s]"}},"8d122cfdb4ec4cdaacd9ab2b086e02c8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ada487ebafa94fb1af6ed7d5db8c02e4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e5be7eca407144b5b8e55edd794d3fff":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fce1711007e242949a68e3f7e0802b3a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c77ea19bfd1345b5a8863051f873ff79":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"bea0cb9c7f5647a4a56f83a345b6c17a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"32ca9d8a5da64488b128c0c50bdb4647":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}